{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d1042-9b52-4e9f-bce4-0bcd7eb15d48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![NCAR UCAR Logo](img/NCAR_CISL_NSF_banner.jpeg)\n",
    "# Hands-On Session Using OpenACC in MPAS-A\n",
    "\n",
    "By: Daniel Howard [dhoward@ucar.edu](mailto:dhoward@ucar.edu), Consulting Services Group, CISL & NCAR \n",
    "\n",
    "Date: April 28th 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1ca32-c6ce-4ac3-8aa4-0fa7771c6560",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In this notebook, we explore the GPU enabled [MPAS-A](http://mpas-dev.github.io/atmosphere/OpenACC/index.html) (Model Prediction Across Scales-Atmosphere) to apply techniques learned from MiniWeather and implementing OpenACC to develop for GPUs. \n",
    "\n",
    "* Review of exercises from prior OpenACC/MiniWeather sessions Part 1 and Part 2\n",
    "* MPAS-Atmosphere model overview\n",
    "* Managing GPU data in large software projects\n",
    "* Assessing performance of extracted GPU kernels in MPAS-A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb6b56-f032-42a0-a6c5-84ccece39ad8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " Head to the [NCAR JupyterHub portal](https://jupyterhub.hpc.ucar.edu/stable) and __start a JupyterHub session on Casper login__ (or batch nodes using 1 CPU, no GPUs) and open the notebook in `05_DirectivesOpenACC/05p2_openACC_miniWeather_Tutorial.ipynb`. Be sure to clone (if needed) and update/pull the NCAR GPU_workshop directory.\n",
    "\n",
    "```shell\n",
    "# Use the JupyterHub GitHub GUI on the left panel or the below shell commands\n",
    "git clone git@github.com:NCAR/GPU_workshop.git\n",
    "git pull\n",
    "```\n",
    "\n",
    "# Workshop Etiquette\n",
    "* Please mute yourself and turn off video during the session.\n",
    "* Questions may be submitted in the chat and will be answered when appropriate. You may also raise your hand, unmute, and ask questions during Q&A at the end of the presentation.\n",
    "* By participating, you are agreeing to [UCARâ€™s Code of Conduct](https://www.ucar.edu/who-we-are/ethics-integrity/codes-conduct/participants)\n",
    "* Recordings & other material will be archived & shared publicly.\n",
    "* Feel free to follow up with the GPU workshop team via Slack or submit support requests to [support.ucar.edu](https://support.ucar.edu)\n",
    "    * Office Hours: Asynchronous support via [Slack](https://ncargpuusers.slack.com) or schedule a time with an organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e08459-56ad-4ee5-bea7-9a988b0e15c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Notebook Setup\n",
    "Set the `PROJECT` code to a currently active project, ie `UCIS0004` for the GPU workshop, and `QUEUE` to the appropriate routing queue depending on if during a live workshop session (`gpuworkshop`), during weekday 8am to 5:30pm MT (`gpudev`), or all other times (`casper`). Due to limited shared GPU resources, please use `GPU_TYPE=gp100` during the workshop. Otherwise, set `GPU_TYPE=v100` (required for `gpudev`) for independent work. See [Casper queue documentation](https://arc.ucar.edu/knowledge_base/72581396#StartingCasperjobswithPBS-Concurrentresourcelimits) for more info.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce23ae-c614-4c46-ab85-c80484f0655d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export PROJECT=UCIS0004\n",
    "export QUEUE=gpudev\n",
    "export GPU_TYPE=v100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bb660-24a0-4b0c-9abd-e8b72839fa01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Review of MiniWeather Performance Optimization\n",
    "At the end of last session, MiniWeather was suggested to use `async` and predominantly `collapse` clauses to achieve optimal performance across the runtime. Using `NX=1024` and `NZ=512`, the most expensive kernel in terms of compute time was at [__Line 231__](../05_DirectivesOpenACC/fortran/miniWeather_mpi_openacc.F90#L231) in the `semi_discrete_step` subroutine, with `NVCOMPILER_ACC_TIME` statistics highlighted below:\n",
    "\n",
    "```shell\n",
    "/glade/u/home/dhoward/GPU_workshop/05_DirectivesOpenACC/fortran/miniWeather_mpi_exercise2.F90\n",
    "semi_discrete_step  NVIDIA  devicenum=0\n",
    "time(us): 62,147\n",
    "257: compute region reached 924 times\n",
    "257: kernel launched 924 times\n",
    "grid: [16384]  block: [128]\n",
    "device time(us): total=62,147 max=70 min=66 avg=67\n",
    "elapsed time(us): total=76,527 max=87 min=80 avg=82\n",
    "257: data region reached 1848 times\n",
    "```\n",
    "\n",
    "The __line number__ in the previous source file is listed at the far left when describing a compute or data region. The name of the subroutine is also given where the kernel is located. The arrangement of __gang/worker/vector__ units is provided by the __grid__, ie number and arrangement of __gangs__, and block, ie __vector length__ times the number of __workers__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56673f67-12cb-45d6-a9f6-aea341492f9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Running this version with the NVIDIA NSight Systems Profiler, we can get a visual representation of the model runtime.\n",
    "![Profile of MiniWeather - Baseline](img/Profile_MiniWeather_Baseline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf3b06-f85d-4417-9ca8-1c1407480789",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This timeline shows the kernels running on the GPU runtime in the upper __blue__ compute kernels, __pink__ device to host transfers, and __aquamarine__ host to device transfers segments. The lower segments show the CPU runtime in __blue__ compute kernel launches, __red__ data directives/regions, and beige __wait/synchronize__ sections.\n",
    "\n",
    "The bright blue highlights the most expensive GPU kernel in the `semi_discrete_step` subroutine with the associated launch call from the CPU highlighted earlier in the timeline.\n",
    "\n",
    "![Profile of MiniWeather - Baseline timeline only](img/Profile_MiniWeather_Baseline_cropped.png)\n",
    "\n",
    "Since we used `async`, the GPU kernels run right after one another without any kernel launch/exit costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b6af5-4c1c-4c6a-9b42-eb4eaf7df984",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "If we did not use `async`, the profile would look like this and time would be lost as the CPU waits between every kernel launch and must incur kernel launch/exit costs between scheduling each kernel.\n",
    "\n",
    "![Profile of MiniWeather - No async](img/Profile_MiniWeather_noasync.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae967af-8ba7-4b02-81e5-32f389501137",
   "metadata": {},
   "source": [
    "## MiniWeather - Testing different kernel launch configurations and clauses\n",
    "Below are some performance statistics on the previously proposed alternate kernel configuration experiments\n",
    "\n",
    "| MiniWeather Kernel L231, `semi_discrete_step` | Avg. Device Time (s) |\n",
    "|---|---|\n",
    "| BaseLine (on V100) - auto `vector_length(128)`        | 67      |\n",
    "| clause - `gang/worker/vector`      | 1017      |\n",
    "| clause - `worker/vector` (Move NUM_VARS innermost, seq)     | 2844      |\n",
    "| clause - `gang/vector` (Move NUM_VARS innermost, seq)     | 79      |\n",
    "| clause - `tile(32,32,NUM_VARS)`      | 30      |\n",
    "| clause - `tile(*,*,*)` -> 32,4,32   | 175      |\n",
    "| clause - `collapse(3) vector_length(32)` | 113      |\n",
    "| clause - `collapse(3) vector_length(256)` | 67      |\n",
    "| clause - `collapse(3) vector_length(512)` | 67      |\n",
    "| clause - `collapse(3) vector_length(1024)` | 75      |\n",
    "\n",
    "1. __Why do you think the `tile()` clause specifying the outermost loop with the `NUM_VARS` variable was most performant?__\n",
    "2. __Using `worker/vector`, the profiler shows `grid: [1]  block: [32x4]`. Why is this arrangement the least performant?__\n",
    "3. __Did you find any better configurations for this or other kernels in MiniWeather? Explain why it performed better.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c156991-f82a-4b05-8f34-bff0ef320f55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## MPAS-A Overview\n",
    "We will now look at a real world production model __MPAS-A__ and how this model leveraged OpenACC to refactor towards GPU devices.\n",
    "\n",
    "<img src=\"img/MPAS-var-res_mesh.png\" alt=\"Global Voronoi mesh\" style=\"width:250px;\"/>\n",
    "\n",
    "<img src=\"img/MPAS-grid_diagram.png\" alt=\"MPAS grid diagram\" style=\"width:300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45375814-e803-4c61-9c8b-301c275b5c49",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "So far, only the v6.x Atmosphere core has been ported to GPUs and is freely available to review via their [website](https://mpas-dev.github.io/atmosphere/OpenACC/index.html) and the stable [v6.x](https://github.com/MPAS-Dev/MPAS-Model/tree/atmosphere/v6.x-openacc) or v7.x [develop-openacc](https://github.com/MPAS-Dev/MPAS-Model/tree/atmosphere/develop-openacc) branches on GitHub. Some work has also been done on the MPAS-Ocean core given this [presentation](https://www.lanl.gov/org/padwp/adx/computational-physics/parallelcomputing/_assets/docs/2020-student-projects/Ashwath_PCSRI_Final_Presentation.pdf) by PhD student Ashwath Venkataraman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c39c0d-d1a4-4144-b968-7a1642db071e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Managing GPU data in MPAS-A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c988f2d-689b-476d-8cc8-c3b7ba923dda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## MPAS-A Kernel Extraction\n",
    "We will focus on the `atm_compute_vert_imp_coefs_work` subroutine and kernels. This is the [link](https://github.com/MPAS-Dev/MPAS-Model/blob/498393d2c5cf36f73db8925d717ae449c3660d40/src/core_atmosphere/dynamics/mpas_atm_time_integration.F#L2109) to the code in the full model codebase and here is the [link](mpas_atm_compute_vert_imp_coefs_work.F90) to the extracted kernel.\n",
    "\n",
    "The extracted kernel simply utilizes randomized input data as we will be focusing on optimizing the performance of the subroutine's kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8f9f1-1e59-4f52-b90a-edd127762330",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## MPAS-A Kernel Optimization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
