{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bff3b3-c704-45b7-83c9-3ce1af3d088f",
   "metadata": {},
   "source": [
    "![NCAR UCAR Logo](../../NCAR_CISL_NSF_banner.jpeg)\n",
    "# Hands-On Session with Nsight Systems and Compute\n",
    "\n",
    "By: Brett Neuman [bneuman@ucar.edu](mailto:bneuman@ucar.edu), Consulting Services Group, CISL & NCAR\n",
    "\n",
    "Date: June 16th 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e5f84-4546-4c11-89ff-7f1911b96164",
   "metadata": {},
   "source": [
    "In this notebook we explore profiling of the mini-app [MiniWeather](https://github.com/mrnorman/miniWeather) to present profiling techniques and code examples. We will cover:\n",
    "\n",
    "1. Overview of Profiling and Performance Sampling Tools\n",
    "   * Typical development workflows with profiling tools\n",
    "2. NSight Systems for Overview Analysis of GPU Program Runtimes\n",
    "   * How to generate nsys reports and command line parameters\n",
    "   * Analysis of nsys reports and investigating the program timeline\n",
    "   * Generating NSight Compute profiling commands from nsys reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e95164-4a3e-469e-9980-9901c56b933b",
   "metadata": {},
   "source": [
    "Head to the [NCAR JupyterHub portal](https://jupyterhub.hpc.ucar.edu/stable) and __start a JupyterHub session on Casper login__ (or batch nodes using 1 CPU, no GPUs) and open the notebook in `10_HandsOnNsight/nsys/10_HandsOnNsight_nsys.ipynb`. Be sure to clone (if needed) and update/pull the NCAR GPU_workshop directory.\n",
    "\n",
    "```shell\n",
    "# Use the JupyterHub GitHub GUI on the left panel or the below shell commands\n",
    "git clone git@github.com:NCAR/GPU_workshop.git\n",
    "git pull\n",
    "```\n",
    "\n",
    "# Workshop Etiquette\n",
    "* Please mute yourself and turn off video during the session.\n",
    "* Questions may be submitted in the chat and will be answered when appropriate. You may also raise your hand, unmute, and ask questions during Q&A at the end of the presentation.\n",
    "* By participating, you are agreeing to [UCAR’s Code of Conduct](https://www.ucar.edu/who-we-are/ethics-integrity/codes-conduct/participants)\n",
    "* Recordings & other material will be archived & shared publicly.\n",
    "* Feel free to follow up with the GPU workshop team via Slack or submit support requests to [support.ucar.edu](https://support.ucar.edu)\n",
    "    * Office Hours: Asynchronous support via [Slack](https://ncargpuusers.slack.com) or schedule a time with an organizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d09968-ce4f-4785-b50f-2778aedceed0",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "Set the `PROJECT` code to a currently active project, ie `UCIS0004` for the GPU workshop, and `QUEUE` to the appropriate routing queue depending on if during a live workshop session (`gpuworkshop`), during weekday 8am to 5:30pm MT (`gpudev`), or all other times (`casper`). Due to limited shared GPU resources, please use `GPU_TYPE=gp100` during the workshop. Otherwise, set `GPU_TYPE=v100` (required for `gpudev`) for independent work. See [Casper queue documentation](https://arc.ucar.edu/knowledge_base/72581396#StartingCasperjobswithPBS-Concurrentresourcelimits) for more info.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be7dd0-4e80-498b-957f-6b338fc7620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export PROJECT=UCIS0004\n",
    "export QUEUE=gpudev\n",
    "export GPU_TYPE=gp100\n",
    "\n",
    "module load nvhpc/22.2 &> /dev/null\n",
    "export PNETCDF_INC=/glade/u/apps/dav/opt/pnetcdf/1.12.2/openmpi/4.1.1/nvhpc/22.2/include\n",
    "export PNETCDF_LIB=/glade/u/apps/dav/opt/pnetcdf/1.12.2/openmpi/4.1.1/nvhpc/22.2/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc10cf9-9763-430d-93c2-9e5d8c7c5ce7",
   "metadata": {},
   "source": [
    "## Profilers - Why Bother?\n",
    "\n",
    "So you have some code.  Maybe you own it, maybe you’re inheriting it, maybe you’re trying to improve it, maybe you’re just trying to keep it operational. \n",
    "\n",
    "If you’re looking to **understand, improve performance, or make informed decisions** on your code in a **timely** fashion, profiling is a **good place to start**.\n",
    "\n",
    "**The profiler does not make decisions for you.** \n",
    "Profilers provide information that could lead to more efficient use of resources for your code!  Be mindful that profiling can add significant runtime overhead to your application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9572fa4-2000-4476-84f2-7e73e7457427",
   "metadata": {},
   "source": [
    "## How to get there\n",
    "1. Profile your code!\n",
    "\n",
    "2. Make sure you have your baseline performance\n",
    "   * Performance is relative here\n",
    "   * Your baseline should be a realistic run of the application (real data, reasonable runtime)\n",
    "\n",
    "\n",
    "3. Attempt to find potential performance gains using profiling tools, your experience, and working around your constraints\n",
    "    \n",
    "   * Common project constraints include:\n",
    "        \n",
    "        \n",
    "     * cluster configurations\n",
    "     * hardware architectures (CPU/GPU/NIC types)\n",
    "     * memory\n",
    "     * flow control (simple instructions vs branching instructions)\n",
    "     * programming language\n",
    "     * development time\n",
    "     \n",
    "   * Tools can give you insight on what sections of code are using up significant runtime \n",
    "     * A function with the highest runtime often has highest potential to be optimized .. **but not always**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bbf08-cc7e-4c9a-bf8b-d6ea45de4d75",
   "metadata": {},
   "source": [
    "## Profiling data collection methods\n",
    "\n",
    "1. **Sampling**\n",
    "   * Collect data at a regular interval, or sampling frequency, to understand how much time is spent in a function or application\n",
    "2. **Concurrency**\n",
    "   * Identifying shared resource bottlenecks, communication overhead, and thread or kernel inefficiencies via call stack traces\n",
    "3. **Memory**\n",
    "   * Gathers information on data movement, allocation, and resource availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62f56a-8c66-4c8a-b8c3-6a0a3f7eaa1c",
   "metadata": {},
   "source": [
    "## The focus of our session\n",
    "In this session we will focus on profiling code on clusters with NVidia GPUs in the role of a researcher.  Our interest is in performant threads, kernels, GPU utilization, and memory efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2343ce-f48a-407d-9032-8a992edc4f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NSight Systems and Compute\n",
    "\n",
    "The Nsight Systems and Compute are used to profile, debug, and optimize applications that utilize Nvidia GPUs.  You can follow along if you have Nsight Systems installed on your local machine.\n",
    "\n",
    "Download: https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2022-2\n",
    "\n",
    "Casper runs Nsys version `2021.2.4.12`\n",
    "\n",
    "![NSight Workflow Diagram](img/Nsight-Diagram.png)\n",
    "\n",
    "## NSight Systems `nsys`\n",
    "\n",
    "Workload level analysis:\n",
    "* Visualize algorithms, instruction flow, data flow, and scaling out to multiple nodes\n",
    "* Identify areas to optimize within the code\n",
    "* Maximize computational and memory utilization on the GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b89dd4-5053-4266-994a-bee02c434c69",
   "metadata": {},
   "source": [
    "### The NSight Systems Profiling Model\n",
    "\n",
    "The Nsight profiling model is based on the **Client Server** model.  The **Client** is your the machine you will use to view reports generated by your code profiling.  The **Server** is the node you run GPU code on and generate the profiling report from.  NVidia refers to this as the **Two Phase** approach to profiling.  A good workflow for profiling your code using the Client Server model would look like:\n",
    "\n",
    "![NSight Workflow Diagram](img/Nsight-Workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12cec7-fbd9-49a6-be96-b3235eadc515",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPU kernel generation\n",
    "\n",
    "Previously, we ran ACC directives on our miniWeather application.  Compilers handle the conversion into GPU code behind the scenes but it is important to note that ACC directives are converted into a NVidia CUDA kernel.  These kernels can be analyzed for performance using Nsight Systems and Compute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d109466-93b9-40da-a45b-0ea6ad09461d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# miniWeather App OpenACC Profiling Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47020066-393a-4bfd-a546-99abfadb7d89",
   "metadata": {},
   "source": [
    "## **Baseline**: Profile Generation and Analysis\n",
    "\n",
    "We're going to profile the miniweather application using the most basic version of `!$acc loop parallel` without any additional flags to help the compiler generate efficient parallel loops.  This might be a first step to converting a CPU based function into an OpenACC.  Remember, your baseline should be a stable working version of your code with a realistic dataset and runtime.  Here we're looking at one example of this implementation on the `semi_discrete_step` subroutine.\n",
    "\n",
    "![NSight Workflow Diagram](img/miniweather_basicacc.png)\n",
    "\n",
    "## Setting up a baseline\n",
    "\n",
    "The Nsight Systems profile launch within this script:\n",
    "\n",
    "``` shell\n",
    "nsys profile -o miniweather_baseline fortran/build/openacc -t openacc,mpi \n",
    "```\n",
    "\n",
    "### Notable flags for `nsys profile`:\n",
    "\n",
    "* -t (--trace) parameters: cublas, cuda, cudnn, nvtx, opengl, openacc, openmp, osrt, mpi, vulkan, none\n",
    "    * `-t openmp,openacc`\n",
    "* -b (--backtrace) parameters: fp, lbr, dwarf, none\n",
    "    * `-b fp`\n",
    "* --cuda-memory-usage parameters: true, false\n",
    "    * `--cuda-memory-usage=true`\n",
    "* --mpi-impl parameters: openmpi, mpich\n",
    "    * `--mpi-impl=openmpi`\n",
    "* -o\n",
    "    * `-o myreport`\n",
    "    * Names the generated profiling report\n",
    "* --stats\n",
    "    * `--stats=true`\n",
    "    * Generate data file to analyze within the CLI\n",
    "    * Takes time to generate\n",
    "* -h: help with explanations for all `nsys` commands plus sub commands\n",
    "    * Run below cells to see help text\n",
    "\n",
    "Some of these options can add significant profiler overhead to your application.\n",
    "\n",
    "Additional options for CLI profiling can be found on the NVidia NSight CLI documentation:\n",
    "\n",
    "https://docs.nvidia.com/nsight-systems/2020.3/profiling/index.html#cli-installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e6737-051c-4a93-80ee-d29a53d92d29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsys -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa0625-5eba-48c6-b003-73024f73ff82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsys profile -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c7afd-1448-4729-bb43-b64c29fb8a51",
   "metadata": {},
   "source": [
    "## Launching the Profiler on Casper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce822dfa-d646-4e2f-9278-cb7fe8afdfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment to prevent repeat runs while testing\n",
    "# qsub pbs/pbs_miniweather_baseline.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d2443-c803-43c3-823c-5d5669920c91",
   "metadata": {},
   "source": [
    "You will see a `.qdrep` file after this job has finished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505271cb-dfcc-4779-9f6c-bfd7572139d2",
   "metadata": {},
   "source": [
    "## Quick Analysis via CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd97c3a-862b-4747-9a5d-efb5779a4546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using reports/miniweather_baseline.sqlite for SQL queries.\n",
      "Running [/glade/u/apps/dav/opt/cuda/11.4.0/nsight-systems-2021.2.4/target-linux-x64/reports/cudaapisum.py reports/miniweather_baseline.sqlite]... \n",
      "\n",
      " Time(%)  Total Time (ns)  Num Calls    Average      Minimum     Maximum     StdDev            Name        \n",
      " -------  ---------------  ---------  ------------  ----------  ----------  ---------  --------------------\n",
      "    98.9  311,045,408,877    829,502     374,978.5         480   4,110,831  672,951.6  cuStreamSynchronize \n",
      "     0.6    1,952,049,331    414,751       4,706.6       2,995   1,276,614    3,407.5  cuLaunchKernel      \n",
      "     0.1      360,215,231     92,188       3,907.4       2,308     392,225    2,940.6  cuMemcpyHtoDAsync_v2\n",
      "     0.1      353,236,646     92,374       3,824.0       2,242   1,474,974    6,696.5  cuMemcpyDtoHAsync_v2\n",
      "     0.1      328,508,188     46,186       7,112.7       1,109   1,278,036   59,376.3  cuCtxSynchronize    \n",
      "     0.1      321,497,397    139,066       2,311.8       1,171     207,400      952.4  cuEventRecord       \n",
      "     0.0       57,625,752          2  28,812,876.0  28,797,402  28,828,350   21,883.5  cuMemHostAlloc      \n",
      "     0.0       54,836,720     92,856         590.6         423     250,978    1,077.5  cuEventSynchronize  \n",
      "     0.0        3,205,420         31     103,400.6       1,358   1,425,718  337,926.8  cuMemAlloc_v2       \n",
      "     0.0        1,062,003          2     531,001.5       6,018   1,055,985  742,438.8  cuMemAllocHost_v2   \n",
      "     0.0          378,549          1     378,549.0     378,549     378,549        0.0  cuModuleLoadDataEx  \n",
      "     0.0           45,674          4      11,418.5       2,677      25,152   10,628.6  cuMemsetD32Async    \n",
      "     0.0           34,418         26       1,323.8         285      12,870    2,521.0  cuEventCreate       \n",
      "     0.0           13,140          1      13,140.0      13,140      13,140        0.0  cuStreamCreate      \n",
      "     0.0            2,444          1       2,444.0       2,444       2,444        0.0  cuInit              \n",
      "\n",
      "Running [/glade/u/apps/dav/opt/cuda/11.4.0/nsight-systems-2021.2.4/target-linux-x64/reports/gpukernsum.py reports/miniweather_baseline.sqlite]... \n",
      "\n",
      " Time(%)  Total Time (ns)  Instances    Average     Minimum    Maximum    StdDev               Name            \n",
      " -------  ---------------  ---------  -----------  ---------  ---------  --------  ----------------------------\n",
      "    34.8  107,763,085,030     46,083  2,338,456.4  2,319,212  2,593,737   7,323.0  compute_tendencies_z_369_gpu\n",
      "    22.5   69,648,080,748     46,083  1,511,361.7  1,493,267  1,812,785  16,927.7  compute_tendencies_x_278_gpu\n",
      "    22.3   69,197,111,596     46,083  1,501,575.7  1,383,189  1,749,617  22,199.8  compute_tendencies_z_334_gpu\n",
      "    10.9   33,900,055,922     92,166    367,815.2    357,149    503,131   5,227.3  semi_discrete_step_231_gpu  \n",
      "     9.1   28,296,053,744     46,083    614,023.7    602,971    748,570   3,340.8  compute_tendencies_x_308_gpu\n",
      "     0.2      641,650,166     46,083     13,923.8     12,288     18,624     372.0  set_halo_values_z_452_gpu   \n",
      "     0.1      288,514,354     46,083      6,260.8      5,408     14,560     261.2  set_halo_values_x_395_gpu   \n",
      "     0.1      281,057,530     46,083      6,098.9      5,855     14,624     204.3  set_halo_values_x_418_gpu   \n",
      "     0.0          172,575          2     86,287.5     78,335     94,240  11,246.5  reductions_871_gpu          \n",
      "     0.0           19,680          2      9,840.0      9,280     10,400     792.0  reductions_871_gpu__red     \n",
      "\n",
      "Running [/glade/u/apps/dav/opt/cuda/11.4.0/nsight-systems-2021.2.4/target-linux-x64/reports/gpumemtimesum.py reports/miniweather_baseline.sqlite]... \n",
      "\n",
      " Time(%)  Total Time (ns)  Operations  Average  Minimum   Maximum    StdDev       Operation     \n",
      " -------  ---------------  ----------  -------  -------  ---------  --------  ------------------\n",
      "    54.0      471,292,258      92,188  5,112.3      864  1,370,900   6,557.4  [CUDA memcpy HtoD]\n",
      "    46.0      402,122,357      92,374  4,353.2      896  1,272,853  42,145.0  [CUDA memcpy DtoH]\n",
      "     0.0            3,295           4    823.8      768        864      40.2  [CUDA memset]     \n",
      "\n",
      "Running [/glade/u/apps/dav/opt/cuda/11.4.0/nsight-systems-2021.2.4/target-linux-x64/reports/gpumemsizesum.py reports/miniweather_baseline.sqlite]... \n",
      "\n",
      "     Total      Operations  Average  Minimum   Maximum    StdDev       Operation     \n",
      " -------------  ----------  -------  -------  ----------  -------  ------------------\n",
      " 4,640,115.031      92,374   50.232    0.008  16,383.906  543.091  [CUDA memcpy DtoH]\n",
      " 2,982,487.461      92,188   32.352    0.125  16,384.000   76.168  [CUDA memcpy HtoD]\n",
      "         0.031           4    0.008    0.008       0.008    0.000  [CUDA memset]     \n",
      "\n",
      "Running [/glade/u/apps/dav/opt/cuda/11.4.0/nsight-systems-2021.2.4/target-linux-x64/reports/osrtsum.py reports/miniweather_baseline.sqlite]... \n",
      "\n",
      " Time(%)  Total Time (ns)  Num Calls      Average        Minimum        Maximum           StdDev                 Name          \n",
      " -------  ---------------  ---------  ---------------  -----------  ---------------  ----------------  ------------------------\n",
      "    33.3  987,640,768,804        107  9,230,287,558.9        1,161  328,766,957,311  50,003,634,104.2  epoll_wait              \n",
      "    33.3  986,559,928,564     61,088     16,149,815.5        1,030  329,169,307,528   1,883,234,444.9  poll                    \n",
      "    22.2  659,270,247,276        167  3,947,726,031.6   42,623,923  329,639,298,880  25,355,113,168.4  select                  \n",
      "    11.1  328,094,330,739        656    500,143,796.9  500,041,057      500,223,002          18,299.5  pthread_cond_timedwait  \n",
      "     0.1    1,724,974,920        708      2,436,405.3        3,076        9,646,299       2,564,917.6  pwrite                  \n",
      "     0.0      466,505,517     93,319          4,999.0        1,002       28,009,889         168,578.5  ioctl                   \n",
      "     0.0      288,069,694      1,340        214,977.4        1,961       69,167,686       2,062,232.5  open                    \n",
      "     0.0      162,721,610      4,757         34,206.8        1,000      136,774,462       1,983,215.8  read                    \n",
      "     0.0       83,935,099         29      2,894,313.8       20,654       36,350,795       8,714,027.3  pthread_cond_wait       \n",
      "     0.0       34,064,040          1     34,064,040.0   34,064,040       34,064,040               0.0  truncate                \n",
      "     0.0       29,334,013      5,797          5,060.2        1,260           34,663           1,278.6  openat                  \n",
      "     0.0       18,916,304          6      3,152,717.3    1,933,235        7,221,737       2,008,494.4  posix_fallocate         \n",
      "     0.0       14,754,930        362         40,759.5        1,178           94,498          26,597.0  write                   \n",
      "     0.0       13,730,760        800         17,163.5        1,002          511,828          18,029.7  fgets                   \n",
      "     0.0       13,530,359      1,824          7,418.0        1,034           45,428           4,168.8  fcntl                   \n",
      "     0.0       10,610,390        100        106,103.9       67,392        1,143,113         119,644.2  pread                   \n",
      "     0.0        7,407,214         79         93,762.2        4,074        2,069,019         289,674.7  mmap64                  \n",
      "     0.0        2,023,120          7        289,017.1       87,286          704,188         273,939.8  munmap                  \n",
      "     0.0        1,743,626         11        158,511.5      135,661          183,676          16,536.6  pthread_create          \n",
      "     0.0        1,641,874        179          9,172.5        1,727          119,641          13,449.5  fopen                   \n",
      "     0.0        1,625,239          9        180,582.1       17,973        1,009,903         315,363.9  sem_timedwait           \n",
      "     0.0        1,365,161        229          5,961.4        2,627          109,471          11,292.9  mmap                    \n",
      "     0.0        1,303,347         30         43,444.9       23,810          100,760          17,623.9  pthread_mutex_lock      \n",
      "     0.0        1,286,497          6        214,416.2       61,355          450,401         132,760.0  pthread_join            \n",
      "     0.0        1,139,803          7        162,829.0      161,679          165,544           1,313.1  usleep                  \n",
      "     0.0          998,091        169          5,905.9        2,644           45,790           4,638.6  fclose                  \n",
      "     0.0          982,047          1        982,047.0      982,047          982,047               0.0  fork                    \n",
      "     0.0          622,275        373          1,668.3        1,052            9,440           1,018.0  socket                  \n",
      "     0.0          604,814         99          6,109.2        3,066           22,168           2,747.4  open64                  \n",
      "     0.0          561,750          4        140,437.5        1,537          555,991         277,036.1  recv                    \n",
      "     0.0          428,804         23         18,643.7        1,194           40,633          11,147.7  writev                  \n",
      "     0.0          299,150          1        299,150.0      299,150          299,150               0.0  ftruncate               \n",
      "     0.0          252,765         55          4,595.7        1,000           16,299           4,538.4  recvmsg                 \n",
      "     0.0          191,132         57          3,353.2        1,004           10,467           2,386.2  mprotect                \n",
      "     0.0          173,182         87          1,990.6        1,005           10,798           1,223.1  epoll_ctl               \n",
      "     0.0          142,270         36          3,951.9        1,346           17,523           4,673.2  sendmsg                 \n",
      "     0.0          142,268         29          4,905.8        2,285           21,020           4,158.8  pthread_cond_broadcast  \n",
      "     0.0          141,888         13         10,914.5        1,926           73,755          19,303.3  shmget                  \n",
      "     0.0          132,897         17          7,817.5        1,880           20,340           6,390.6  fread                   \n",
      "     0.0          107,304         45          2,384.5        1,010           12,512           2,311.5  fwrite                  \n",
      "     0.0           93,083          8         11,635.4        1,010           39,867          12,875.3  listen                  \n",
      "     0.0           66,044          5         13,208.8        5,001           32,386          11,680.4  shutdown                \n",
      "     0.0           57,357          2         28,678.5        8,355           49,002          28,741.8  connect                 \n",
      "     0.0           56,751          6          9,458.5        5,408           14,082           3,481.1  getdelim                \n",
      "     0.0           47,714          9          5,301.6        1,194           12,703           3,894.4  fgetc                   \n",
      "     0.0           34,170         16          2,135.6        1,094            3,660             700.0  bind                    \n",
      "     0.0           32,437          3         10,812.3        1,544           20,221           9,339.3  send                    \n",
      "     0.0           24,649          5          4,929.8        4,294            5,844             653.9  socketpair              \n",
      "     0.0           17,315          6          2,885.8        2,188            3,803             628.6  pipe                    \n",
      "     0.0           16,192          2          8,096.0        7,430            8,762             941.9  shmdt                   \n",
      "     0.0           11,878          5          2,375.6        1,129            6,104           2,104.0  sigaction               \n",
      "     0.0            9,314          3          3,104.7        2,156            4,708           1,396.3  pthread_rwlock_trywrlock\n",
      "     0.0            8,542          2          4,271.0        3,595            4,947             956.0  shmat                   \n",
      "     0.0            8,515          2          4,257.5        3,651            4,864             857.7  accept                  \n",
      "     0.0            6,379          2          3,189.5        2,643            3,736             772.9  process_vm_writev       \n",
      "     0.0            5,661          1          5,661.0        5,661            5,661               0.0  pipe2                   \n",
      "     0.0            4,542          4          1,135.5        1,016            1,339             148.9  shmctl                  \n",
      "     0.0            3,075          1          3,075.0        3,075            3,075               0.0  pthread_mutex_trylock   \n",
      "     0.0            1,470          1          1,470.0        1,470            1,470               0.0  recvfrom                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nsys stats reports/miniweather_baseline.qdrep | grep -v \"SKIPPED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb655671-72ba-42c7-b511-3914c6964fec",
   "metadata": {},
   "source": [
    "\n",
    "This output will look familiar if you have used `nvprof` to profile codes previously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45811ce9-0eba-4be8-b03a-5451b58e6a7c",
   "metadata": {},
   "source": [
    "## Timeline Analysis via Nsight Systems GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b45db-2a4a-45c7-84ac-60cd51ea1b52",
   "metadata": {},
   "source": [
    "### Transfer or View the Report\n",
    "\n",
    "Reports for analysis are located in the `reports` folder.  For our baseline we will use the generated report:\n",
    "\n",
    "`miniweather_baseline.qdrep`\n",
    "\n",
    "1. Transfer the `.qdrep` file to your local machine and load in into your local installation of the NSight Systems application\n",
    "    * Download the file by right clicking and selecting `Download` on the JupyterHub browser on the left.  \n",
    "\n",
    "\n",
    "2. Launch a X or VNC session on a GP100 GPU node on Casper.  Launch `nsight-nsys`. \n",
    "   * KB Article to set up VNC: https://kb.ucar.edu/display/RC/Using+remote+desktops+on+Casper+with+VNC\n",
    "   * X session works but can be slow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6dc2f-2e99-4aaa-884d-71e95040acb4",
   "metadata": {},
   "source": [
    "### Nsight Systems GUI\n",
    "\n",
    "Open the file in the NSight Systems application.  Below is the default view upon opening the application.\n",
    "\n",
    "![NSight Default View](img/nsight_defaultview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066589a-530b-4539-9ea7-12fd8c90d260",
   "metadata": {},
   "source": [
    "### Projects\n",
    "\n",
    "![NSight Project View](img/nsight_projectview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77104646-6e9b-42c8-a1b8-eb34b5af4b14",
   "metadata": {},
   "source": [
    "### Navigation\n",
    "\n",
    "![NSight Navigation](img/nsight_navigation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7900d-8d4b-4ffe-8ae6-8f498f23d2d1",
   "metadata": {},
   "source": [
    "### Event Descriptions\n",
    "\n",
    "![NSight Event Description](img/nsight_eventdescription.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9deee-a8e6-46d6-aaf1-bf858f571af7",
   "metadata": {},
   "source": [
    "## Baseline Timeline View\n",
    "\n",
    "`miniweather_baseline.qdrep`\n",
    "\n",
    "![Miniweather Baseline Timeline View](img/miniweather_baseline_timeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16682bff-1181-4445-ba68-ed14a46f9b6e",
   "metadata": {},
   "source": [
    "## Patterns, Gaps, Walltime and Kernels\n",
    "\n",
    "We can find instruction patterns of interest, sections where the GPU is idle, and also view details on which kernel is running at a given time using the Timeline view.  Below is an example of a repeated pattern found in the baseline report.  It will be useful to note that the time to complete this repeated pattern is about 20ms.\n",
    "\n",
    "Note that we zoomed into the timeline significantly.\n",
    "\n",
    "![Miniweather Instruction Pattern](img/miniweather_pattern.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda57ad9-026e-40b8-aca7-6d4e9180a3df",
   "metadata": {},
   "source": [
    "### Stats View\n",
    "\n",
    "Quickly find CUDA API and GPU Kernel instruction runtimes. This is a good place to get ideas on how to make improvements.\n",
    "\n",
    "![NSight Systems Stats View](img/miniweather_statsview_baseline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9e239-2ed5-42e8-ab32-c2b2cf0378e8",
   "metadata": {},
   "source": [
    "## **Asynchronous** Loops Profile\n",
    "\n",
    "I'm using the information that shows about 50% of our runtime in `cuStreamSynchronize` to make changes to the existing `!$acc loop parallel` sections.\n",
    "\n",
    "![Miniweather CUDA Summary](img/miniweather_cudasummary_baseline.png)\n",
    "\n",
    "Modify the ACC loops to perform asynchronously.  OpenACC will no longer wait for the flagged loop to finish before launching another and should pipeline the loop iterations.  We need to include `!$acc wait` flags for sections to allow individual loop sections to finish before operating on a different loop.\n",
    "\n",
    "![Miniweather Async Loop Code](img/miniweather_asyncloop.png)\n",
    "\n",
    "Recompile and profile the code again to see the changes you've made.  Launch the script with the new `nsys profile` command on Casper.\n",
    "\n",
    "``` shell\n",
    "nsys profile -o miniweather_async fortran/build/openacc -t openacc,mpi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003cbcdb-f7dc-4fb4-a5e2-3e3bc0ea5aea",
   "metadata": {},
   "source": [
    "### Asynchronous Analysis\n",
    "\n",
    "`miniweather_async.qdrep`\n",
    "\n",
    "Not a significant change.  The command `CuStreamSynchronize` changed to `CuCtxSynchronize` but still takes almost 50% of the runtime.\n",
    "\n",
    "![Miniweather Async Stats](img/miniweather_async_stats.png)\n",
    "\n",
    "We can see that the memory operations are launching from within the same stream now, suggesting that there is pipelining.\n",
    "\n",
    "![Miniweather Async Pipeline](img/miniweather_baseline_memops.png)\n",
    "\n",
    "We're still spending a lot of time in `CuStreamSynchronize`.  Can we try to improve our parallezation of loops?\n",
    "\n",
    "![Miniweather Async Timeline](img/miniweather_async_timeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88ff14-1651-48af-a1d4-f8a1ea407dc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __Collapsed__ Loops Profile\n",
    "\n",
    "Modify the ACC loops to perform asynchronously and also collapse loops based on how deep the loop structure is.\n",
    "\n",
    "![Miniweather Collapsed Loop Code](img/miniweather_async_collapse.png)\n",
    "\n",
    "Recompile and profile the code again to see the changes you've made.  Launch the script with the new `nsys profile` command on Casper.\n",
    "\n",
    "``` shell\n",
    "nsys profile -o miniweather_async_collapsed fortran/build/openacc -t openacc,mpi\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128edd0-e1f7-4faa-b234-2b4ec30eff16",
   "metadata": {},
   "source": [
    "### __Collapsed__ Loops Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40faa7db-bda3-4908-95cd-771d8c3e5dd6",
   "metadata": {},
   "source": [
    "`miniweather_async_collapsed.qdrep`\n",
    "\n",
    "![Miniweather Collapsed Loop Analysis](img/miniweather_collapsed_walltime.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c846fde-ba40-4334-bb5a-13cac4235ebc",
   "metadata": {},
   "source": [
    "Here is the `CuCtxSynchronize` wait time for the Async profile.  15 seconds spent waiting to launch a new round of instructions.\n",
    "\n",
    "![Miniweather Async Sync Wait Time](img/miniweather_async_synctime.png)\n",
    "\n",
    "The same `CuCtxSynchronize` with the Collapsed loops profile.  Down to 1ms.\n",
    "\n",
    "![Miniweather Collapsed Sync Wait Time](img/miniweather_collapsed_synctime.png)\n",
    "\n",
    "You can also spot additional calls to kernels in between synchronization, so we've improved parallelism.\n",
    "\n",
    "![Miniweather Collapsed Sync Wait Time](img/miniweather_collapsed_instructions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784d1ab-cf5c-4bbd-bc7c-64dc3f33a614",
   "metadata": {},
   "source": [
    "### Output to file and I/O operations\n",
    "\n",
    "After zooming into the timeline for the `miniweather_async_collapsed.qdrep` file you will notice that there is an operation that occurs between kernel operations frequently. \n",
    "\n",
    "![miniweather_collapsed_bubbles](img/miniweather_collapsed_bubbles.png)\n",
    "\n",
    "Hovering over the operation gives us the call stack where we can identify the IO operation.  Here we see it coming from the `_output` subroutine.  Recording the results of your simulation is important but let's see what sort of performance we can get by eliminating the call to `output`.\n",
    "\n",
    "Compare the full timeline view of the `miniweather_async_collapsed.qdrep` and the `miniweather_nooutput.qdrep`.  You'll notice the bubbles are gone and the walltime is 32s compared to 41s (1.28x).  Reducing idle time on the GPU and also reducing memory transfers between host and device give us a good performance gain.\n",
    "\n",
    "![miniweather_collapsed_bubbles](img/miniweather_nobubbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb83e09-6221-4ec7-a761-8ac8b7d4509d",
   "metadata": {},
   "source": [
    "### Expert View\n",
    "\n",
    "Good spot to go for general recommendations based on common GPU problems and can provide hints on where to start optimizing.\n",
    "\n",
    "![NSight Workflow Diagram](img/Expert_Systemview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fdde8-12a8-483b-8210-85ee8a47a7cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other profiling tools\n",
    "\n",
    "There is a lot of profiling work being done in the deep learning and scientific computing spheres. There are other tools available to analyzing training time, visualization insight, and other DL/ML focused profilers:\n",
    "1) DLProf: https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/\n",
    "2) Tensorboard: https://www.tensorflow.org/tensorboard/get_started\n",
    "3) NVidia Tools Extension (NVTX)\n",
    "   * NVIDIA Tools Extension (NVTX) is an API that allows for additional control for profiling your applications.  NVTX can be particularly useful when you have a specific section of your code that you need to gather performance information on.  It can also be a useful intermediate step between the higher level Nsight Systems view and the kernel optimization of Nsight Compute.\n",
    "   * NVTX header file used and code marked to profile specific sections of your larger codebase\n",
    "   * Jiri Kraus (our next workshop presenter) has a very good walkthrough of using NVTX for C/C++: https://developer.nvidia.com/blog/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/\n",
    "\n",
    "FORTRAN Example:\n",
    "```fortran\n",
    "program main\n",
    "  use nvtx\n",
    "\n",
    "  call nvtxStartRange(\"First label\")\n",
    "  do n=1,100\n",
    "    ! Create custom label for each marker\n",
    "    write(itcount,'(i4)') n\n",
    "    ! Range with custom  color\n",
    "    call nvtxStartRange(\"Label \"//itcount,n)\n",
    "    ...\n",
    "    call nvtxEndRange\n",
    "  end do\n",
    "  call nvtxEndRange\n",
    "end program main\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223643f2-e016-4967-8f69-56f70b5aa915",
   "metadata": {},
   "source": [
    "# Launching Nsight Compute with Nsight Systems\n",
    "\n",
    "Information from hovering over a kernel launch instruction:\n",
    "\n",
    "![NCU Timeline View Launch](img/ncu_kernel_info.png)\n",
    "\n",
    "You can also right click on the kernel and see a textual timeline of all instances of that kernel in your application:\n",
    "\n",
    "![NCU Timeline View Launch](img/ncu_kernel_eventsview.png)\n",
    "\n",
    "From here you can right click on the kernel launch instruction in the timeline and analyze it in Nsight Compute.  Select `Analyze the Selected Kernel with NVIDIA Nsight Compute`:\n",
    "\n",
    "![NCU Timeline View Launch](img/ncu_kernel_launch.png)\n",
    "\n",
    "Here is the window to launch Nsight Compute:\n",
    "\n",
    "![NCU Window](img/ncu_launch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf56aa-6267-4865-8d30-9d9f512e6840",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "NVidia Nsight Systems User Guide:\n",
    "https://docs.nvidia.com/nsight-systems/UserGuide/index.html\n",
    "\n",
    "Climate related optimizations for GPUs\n",
    "https://github.com/mrnorman/miniWeather/wiki/A-Practical-Introduction-to-GPU-Refactoring-in-Fortran-with-Directives-for-Climate\n",
    "\n",
    "Overview of common profiling methods\n",
    "https://www.atatus.com/blog/what-is-code-profiling-a-detailed-explanation/#Types-of-Code-Profiling\n",
    "\n",
    "NVTX Walkthrough:\n",
    "https://developer.nvidia.com/blog/cuda-pro-tip-generate-custom-application-profile-timelines-nvtx/\n",
    "\n",
    "OpenACC Best Practices for GPU Refactoring:\n",
    "https://www.openacc.org/sites/default/files/inline-files/OpenACC_Programming_Guide_0_0.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d251c56-f001-4c47-a820-00436ebcc2f2",
   "metadata": {},
   "source": [
    "## Move On to Nsight Compute Profiler Tool\n",
    "\n",
    "[Nsight Compute Profiler](../ncu/10_HandsOnNsight_ncu.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
