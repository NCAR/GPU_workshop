{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b534227-b500-4493-a780-1ef98d17fa0e",
   "metadata": {},
   "source": [
    "![NCAR UCAR Logo](../NCAR_CISL_NSF_banner.jpeg)\n",
    "# Hands On Session with Nsight Systems and Nsight Compute\n",
    "\n",
    "By: Brett Neuman & Daniel Howard, Consulting Services Group, CISL & NCAR \n",
    "\n",
    "[bneuman@ucar.edu](mailto:bneuman@ucar.edu) & [dhoward@ucar.edu](mailto:dhoward@ucar.edu)\n",
    "\n",
    "Date: June 16th, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d6f85-2f37-4069-8d0b-8f42e4a7acb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export PROJECT=UCIS0004\n",
    "export QUEUE=gpudev\n",
    "export GPU_TYPE=gp100\n",
    "\n",
    "module load nvhpc/22.5 openmpi &> /dev/null\n",
    "export PNETCDF_INC=/glade/u/apps/dav/opt/pnetcdf/1.12.3/openmpi/4.1.4/nvhpc/22.5/include\n",
    "export PNETCDF_LIB=/glade/u/apps/dav/opt/pnetcdf/1.12.3/openmpi/4.1.4/nvhpc/22.5/lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e7d24-70e7-478c-92d1-daddbe51520d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## What is a Profiler?\n",
    "Profilers are tools that __samples__ and measure performance characteristics of an executable across its runtime. This information is intended to aid program optimization and performance engineering.\n",
    "\n",
    "Profiler software that are supported at NCAR include __Arm Map__, __Nsight Systems__, and __Nsight Compute__. All of these tools are able to analyze GPU code. Other profilers you may be aware of include TAU, Intel VTune Advisor, HPC Toolkit, and Vampir.\n",
    "\n",
    "Today, we will focus on the NVIDIA Nsight profiling tools and usage techniques of these tools.\n",
    "\n",
    "* __Nsight Systems__ - Provides a high level runtime and trace analysis of the program runtime via a measured timeline of various metrics and GPU kernels across a program.\n",
    "* __Nsight Compute__ - Provides an in depth level assessment of individual GPU kernel performance and how various GPU resources are utilized across many different metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b321b-61b2-4a5f-8fbd-fb112302acd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Nsight Systems and Nsight Compute combined screenshot](img/NsightSystemsCompute.jpeg)\n",
    "\n",
    "Nsight Systems (left) shows a timeline of code runtime.\n",
    "\n",
    "Nsight Compute (right) records and presents extensive performance statistics for individual kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89deffa3-c3d1-4c01-9cb0-3508de16e134",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Profiling Documentation Resources\n",
    "NVIDIA provides extensive documentation for each of these profilers. We will go over basic usage of these tools but to learn more and get the most out of Nsight, consult the below resources:\n",
    "\n",
    "* [Nsight Systems Main Documentation](https://docs.nvidia.com/nsight-systems)\n",
    "* [Nsight Compute Main Documentation](https://docs.nvidia.com/nsight-compute/)\n",
    "* [Nsight Compute Profiling Guide](https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html)\n",
    "* [Nsight Compute Training Resources](https://docs.nvidia.com/nsight-compute/Training/index.html) - Forum, Videos, and Blog Posts curated by NVIDIA\n",
    "\n",
    "An excellent interactive step-by-step tutorial given by Max Katz (NVIDIA) using Nsight Compute to optimize an OpenACC kernel in the BerkeleyGW many-body perturbation theory software can be found at [this Gitlab repository](https://gitlab.com/NERSC/roofline-on-nvidia-gpus). A recorded video on this material is [here](https://www.youtube.com/watch?v=fsC3QeZHM1U).\n",
    "\n",
    "Additionally, the CLI help pages via the `-h` flag for each profiler is a useful quick reference point. Run the below cells to view them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca8f04-704b-4ea3-a71f-de1479a2820a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncu -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d162c-b21b-44ba-8262-21004193b132",
   "metadata": {},
   "source": [
    "## Profiling Workflow\n",
    "![Nsight Workflow](img/Nsight-Workflow.png)\n",
    "\n",
    "When assessing and optimizing performance of software, it is best practice to first profile the overall runtime of the program with Nsight Systems. From there, expensive kernels can be identified and profiled more in depth using Nsight Compute.\n",
    "\n",
    "Iteratively analyse and modify code to optimize performance, up to the amount of effort is worth your time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110520de-8b48-4381-9553-cb0f091a7718",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Nsight Compute\n",
    "After getting a sense of the overall performance of your program with Nsight Systems, use Nsight Compute to dive deeper into the performance of individual GPU kernels.\n",
    "\n",
    "* __CUDA kernel profiler__ (or CUDA kernels generated by OpenACC/OpenMP/Kokkos code)\n",
    "* Curates __performance statistics__ into targeted metrics sections\n",
    "* Able to __select amount of data to collect__ and how it's presented\n",
    "    * More data/compute analysis introduces greater __overhead with profiler usage__\n",
    "* Fully featured __Command Line__ and __User Friendly GUI__ interfaces\n",
    "* Regularly updated and customizable Python based rules for __guided analysis__ and post-processing\n",
    "\n",
    "![Nsight Compute Profiling Overview](img/NCU_Process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d0b4f-6c3f-49dc-916d-e594464a6971",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Preparing Code for Nsight Compute\n",
    "When preparing code for Nsight Compute, an important compile option to add is `-gpu=lineinfo`. __DON'T USE `-pg`, `-g`, or `-G` flags__. The lineinfo flag allows the Source/SASS analysis section of Nsight Compute correlate performance information with specific lines of CUDA and/or OpenACC/OpenMP code.\n",
    "\n",
    "Use the below cell to compile and re-compile MiniWeather after code changes are made. You may also modify the runtime parameters, grid size, and simulation time to investigate how different problem sizes impact performance. Review the generated GPU kernel specifications from the `-Minfo=acc` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da8a05-aed8-42f3-b4ba-02e00988c745",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "export OPENACC_FLAGS=\"-acc -gpu=cc60,cc70,lineinfo\"\n",
    "\n",
    "mpif90 -I${PNETCDF_INC} -Mextend -O0 -DNO_INFORM -c miniWeather_mpi_openacc.F90 -o miniWeather_mpi_openacc.F90.o \\\n",
    "-D_NX=9192 -D_NZ=4096 -D_SIM_TIME=0.1 -D_OUT_FREQ=2.0 -D_DATA_SPEC=DATA_SPEC_THERMAL ${OPENACC_FLAGS} -Minfo=acc\n",
    "\n",
    "mpif90 -Mextend -O3 miniWeather_mpi_openacc.F90.o -o openacc -L${PNETCDF_LIB} -lpnetcdf ${OPENACC_FLAGS}\n",
    "rm -f miniWeather_mpi_openacc.F90.o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ee39c-4ebb-48c3-bd47-248cf8938e61",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Notably, only a short simulation time (enough to cover a few timesteps) is required for us to effectively analyze and optimize model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c163767-11bd-419d-9908-8c23b91a55d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Nsight Compute CLI Options\n",
    "\n",
    "* `-o <report-name>` - Writes output to a `*.ncu-rep` file for analysis via the GUI client\n",
    "    * Without `-o`, analysis is summarized in stdout.\n",
    "* `-f` - Force overwrite of output files\n",
    "* `-c` or `--launch-count` - Specifies the number of kernel launches to profile. Otherwise, all launched kernels are profiled\n",
    "* `-s` or `--launch-skip` - Skips a specified number of kernel launches. Useful for letting the GPU \"warm-up\"\n",
    "* `--set <arg>` - Sets the amount of data collected and kernel metrics measured, i.e. `detailed`, `full`, or others given from `--list-sets` flag\n",
    "    * More data collected requires more redundant runs of GPU kernels and increases profiler overhead\n",
    "* `-k` or `--kernel-name` - Specifies the exact name (see `nsys`) of kernels to be profiled\n",
    "    * Use `-k regex:<expression>` to filter kernels by a regex expression\n",
    "* `--nvtx` - Enables support for NVTX ranges\n",
    "* `--nvtx-include arg` - Filters kernels to profile based on included named NVTX ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb41bf8-11f2-4dcb-a9d4-b45ba436c7fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Generate Nsight Compute Report\n",
    "\n",
    "Here we start with the final version of [miniWeather_mpi_openacc.F90](miniWeather_mpi_openacc.F90). As we analyze performance information from this version, use the generated report to inform code optimizations to experiment with in this source file.\n",
    "\n",
    "First, using the submit script [ncu_bash.sh](ncu_bash.sh), run the Nsight Compute profiler against MiniWeather by running the command `ncu <ncu options> <exec> <exec arguments>`. Useful `ncu` options are listed above but also may be reviewed via `ncu -h`.\n",
    "\n",
    "The first profile run of MiniWeather will profile all kernels using `--sets full` in order to make a baseline (requires redundantly running kernels 73-74 times). After making code changes, modify the Nsight Compute report filename to a descriptive name each time you re-run the below cell to help you keep track of and compare changes between different versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55e317-b799-49eb-b1c8-8c374972c7ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qsub -q $QUEUE -l gpu_type=$GPU_TYPE -A $PROJECT -v NCU_REPORT=\"MW_DivToMult\" ncu_bash.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000875cd-9d3c-4ab8-b81a-3b598f83f644",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "`SHIFT` +  `right click` [MW_baseline.ncu-rep](MW_baseline.ncu-rep) in order to save the Nsight Compute report to your personal machine (or download the file from the left pane explorer). Use your local Nsight Compute client to open the file. Alternatively, after setting `module load nvhpc`, you can run `ncu-ui <report-name>` over a terminal X session or VNC/FastX session on Casper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dfb82-14ee-4f32-87c0-8c0ce251e28c",
   "metadata": {},
   "source": [
    "## Analysis of Nsight Compute Profiles\n",
    "Depending on the option chosen for `--set` and number of metrics measured, the kernel profiling report will contain a selection of different sections for review covering performance metrics of each kernel profiled.\n",
    "\n",
    "When using the GUI, __guided analysis__ as alerted via exclamation point yellow warning signs will suggest specific issues the profiler identifies and tries to suggest solutions. These are automatically triggered Python rules written by Nsight Compute maintainers and experts, which can be further customized or added to. If you need help interpretting this information, hover your mouse over a piece of information and an informative text box will appear to explain.\n",
    "\n",
    "Below, we review a few important sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856d9cf-fe33-4bc8-93d0-0c50c19c8174",
   "metadata": {},
   "source": [
    "## Nsight Compute - GPU Speed of Light\n",
    "![GPU Speed of Light](img/NCU_SoL.png)\n",
    "\n",
    "The GPU Speed of Light section highlights to what percentage is this kernel using the full capability of the GPU, both in terms of Streaming Multiprocesser (SM) occupancy and Memory Throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850caff-4070-4c5c-8c18-a22ca67f71e0",
   "metadata": {},
   "source": [
    "## Nsight Compute - Roofline Analysis\n",
    "![Roofline Analysis](img/NCU_RooflineBounded.png)\n",
    "\n",
    "With at least `--set detailed`, a roofline analysis section is provided. Based on the measured performance, this plot can be used to determine if the kernel is compute or memory bound. Memory bound kernels can perhaps benefit by assigning more compute operations per thread if possible. Compute bound kernels will likely require further analysis for optimization, typically by checking for warp stalls or coallesced memory issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f4180-95a2-4e30-855e-d80f7237781e",
   "metadata": {},
   "source": [
    "## Nsight Compute - Memory Workload Analysis\n",
    "![Nsight Compute Memory Workload Analysis](img/NCU_MemoryWorkload.png)\n",
    "\n",
    "This section provides a detailed analysis of the memory resources of the GPU. In this case, Nsight Compute identifies that there is an imbalance of data movement between the L1 and L2 caches due to uncoalesced memory. To improve this, memory access patterns need to be re-designed within the source code and OpenACC kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173d21c-4f70-4373-8a30-04ded28d471b",
   "metadata": {},
   "source": [
    "## Nsight Compute - Source/SASS and Instruction Hotspots\n",
    "![Nsight Source Analysis](img/NCU_Source.png)\n",
    "\n",
    "Navigated to via the __Source Counters__ section, a heatmap of resource usage and other metrics can be correlated to specfic lines of code within the source files. This can more easily identify which specific areas of your program are causing poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5fab-2ace-4493-aa56-a2e379b8137f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Nsight Compute - Add a Baseline\n",
    "\n",
    "Whenever profiling a program or specific kernel, it is vitally important to record and __set a baseline__ to reference performance changes against. In Nsight Compute, set a baseline by clicking __Add Baseline__ near the top of the main window within the Nsight Compute GUI. Note, you can add multiple \"baselines\" from multiple reports.\n",
    "\n",
    "![Nsight Compute Add Baseline](img/NCU_AddBaseline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f7b09-0a0c-4b94-b36d-e0902ec35714",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Rename a baseline by clicking the __Baseline #__ text label.\n",
    "\n",
    "![Nsight Compute Name Baseline](img/NCU_NameBaseline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4753b3f-d09b-4e6a-979a-3d4591e8a430",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now, __open the new profile report__ or switch to the other tab referencing this report. The baseline performance metrics will now be displayed and compared to the new current report's performance metrics.\n",
    "\n",
    "![Nsight Compute Updated Speed of Light](img/NCU_UpdateSoL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16323380-9d5b-4782-ba87-8e2fbf90329c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Experiment with a Proposed Optimization - Replace Divide with Multiply\n",
    "Noting the __hotspot at line 288__, we can assess if there's a way to re-formulate this line to either reduce redundant operations or refactor the overall algorithm. The metrics provided may be able to provide a hint towards why this line is a bottleneck for MiniWeather.\n",
    "\n",
    "In this case, there are a significant number of warp stalls (see [here](https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#statistical-sampler) for descriptions of types of warp stalls) as well as a much higher number of instructions executed compared to other lines in this kernel. Looking at this line, we see multiple divisions by 12 that could be simplified. Additionally, division is typically more expensive than multiplication within IEEE computational arithmetic.\n",
    "\n",
    "Thus, let's try changing this line to `vals(ll) = (-stencil(1) + 7*stencil(2) + 7*stencil(3) - stencil(4))*0.083333333333333333`. The report that analyses this change is [MW_DivToMult.ncu-rep](MW_DivToMult.ncu-rep)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db9b2e-7c2d-4968-8d91-4961f4fd1d92",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Nsight Compute Source Division to Multiply](img/NCU_DivToMult.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd208d5e-702b-4c32-a7f8-731e9294f8c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## EXERCISE - Adjust MiniWeather Problem Size and Other Optimizations\n",
    "Adjust MiniWeather's problem size using the values `nx=128,512,1024,2048,4096,9192` with `nz=nx/2`. Try more problem sizes if interested. Generate `ncu` reports for each of these problem sizes.\n",
    "\n",
    "Then, open up all the reports and add each one as a named baseline for that problem size. Compare performance between problem sizes.\n",
    "\n",
    "1. __Describe the performance for small problem sizes? What is the SM utilization and memory throughput for small problems?__\n",
    "2. __Is there an optimal problem size?__\n",
    "3. __Do performance or other metrics stop changing after a certain order of magnitude for the problem size?__\n",
    "4. Experiment with and attempt other optimizations/code changes to improve MiniWeather's performance. __What other ways or styles of refactoring might you try to improve performance?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d6df3-87dc-41df-90db-ae643394c68f",
   "metadata": {},
   "source": [
    "## Return to Nsight Systems Profiler Tool\n",
    "\n",
    "[Nsight Systems Profiler](../nsys/10_HandsOnNsight_nsys.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
